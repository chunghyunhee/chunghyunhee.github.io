---
title : "ML05.Backpropagation"
toc : True
---

## 1. cost function and Backpropagation
지난시간에 배웠던 순전파 즉 forward의 방법을 나타내자면 아래와 같다 (이미지 출처: https://gomguard.tistory.com/182) input값에 각 weight를 받으면서 이후의 layer로 넘어가고, 그 layer에서는 특정한 함수 g(input*weight)로 계산되면서 compute가 계속 진행이 된다. 즉 처음에 봤던 regression 형태보다 좀더 hard한 형태의 weight를 주면서 섬세한 작업이 가능할 것이라는 것을 직관적으로 이해가 가능하다. 또한 cost function을 말하면서 계속 설명될 error를 mse로 계산한다면 아래와 같을 수 있다. <br>
![image](https://user-images.githubusercontent.com/49298791/73642791-af29d280-46b5-11ea-9be4-53f9c5bd3b2d.png)

<br>
**(1) cost fucntion** <br>
- neural network를 classification으로 사용하는 경우, binary classification의 경우, output layer의 수는 1개이다. multi-class classification의 경우 output layer의 경우는 k개의 output을 가진다. (dummy의 형태를 가진다)
- 몇 가지 표기법을 정의한다. L은 레이어의 수, s_l은 해당 레이어의 유닛 수, 아웃풋 레이어의 유닛수는 더 간단하게 K라고 한다. 
<br>
- 아래의 cost function에서의 k는 output unit의 수를 의미한다. regularizaton의 cost function은 binary classification에 대한 regualarized cost function이다. 
- neural network의 cost function은 로지스틱 비용함수의 general version이다. 
![image](https://user-images.githubusercontent.com/49298791/73642820-bd77ee80-46b5-11ea-8b13-8d8eb7a15497.png)

- 지난시간에 설명했듯이 신경망에서의 각 단계는 logistic 과 비슷하기 때문에 L의 신경망은 (L-1)의 logistic regression의 식으로 변환 가능하다. 
- 원래 cost function 정의가 hypothesis와 real-value의 차이를 알고자 하는 것이므로, K class에 대하여 모든 벡터의 합을 구하는 것과 동일하다. 

#### Note
1. the double sum simply adds up the logistic regression costs calculated for each cell in the output layer.
2. the triple sum simply adds up the squares of all the individual Θs in the entire network.
3. the i in the triple sum does not refer to training example i


**(2) Backpropagation Algotithm** <br>
- min (cost function) of neural network is Backpropagation algorithm이다. 
- 각 big theta에 대해 partial derivitive를 해야 min값을 구할 수 있다. 
- 하나의 데이터 (x,y)에 대해 neural network의 forward propagation식을 나타내면 아래와 같았다. (cost function을 얻기 위한 forward propagation)


![image](https://user-images.githubusercontent.com/49298791/73642866-d5e80900-46b5-11ea-90ca-c138a301438f.png)

- cost function의 partial derivative는 **backward propagation**을 이용하면 된다.
- $\delta$는 layer L에서의 jth node의 error값이다.
- 신경망으로 얻은 값과 실제값의 차이를 d4,d3,d2까지 구한다(d1은 없다 : a1이 input이기 때문이다). 에러값을 뒤에서부터 끌어서 가져오는 형태이므로, BP라고 부른다.
<br>
- **각 layer마다 $\delta$를 구하는 방법은?**<br>

![image](https://user-images.githubusercontent.com/49298791/73642900-e7c9ac00-46b5-11ea-98df-3f323217a271.png)

- 즉 J($\theta$)의 partial derivative term의 값은 결국 $=a^l_j*dleta^(l+1)_i$임을 나타낸다. 
![image](https://user-images.githubusercontent.com/49298791/73642937-f57f3180-46b5-11ea-98c9-cfc3721aee26.png)

<br>
- 즉 delta의 값이 0으로 수렴할 때까지 계속 반복되면서 theta값을 update한다는 의미가 완성이 된다,


**(3) Backpropagation intuition**<br>
- 역전파알고리즘에 대한 직관적인 이해를 돕기 위해 forward propagation을 잠시 본다,
- (참고로 unbiased unit은 각 layer내의 node의 수로 세지 않는다. )

![image](https://user-images.githubusercontent.com/49298791/73642975-04fe7a80-46b6-11ea-80d2-c9ca25f2aaf0.png)

<br>
- $z^n$은 vectorized theta값에 input값(혹은 이전 layer값)인 x값을 곱하는 형태를 의미한다. $a^n$의 값을 g(z)를 compute한 값을 의미한다. 
- 위의 예의 경우는 $z^3_1$을 계산하는데 weight를 준 계산을 진행한 것이다. 이 형태는 left->right로 이루어 지는 것을 의미하고 right->left를 이해하는 것도 결국은 비슷한 맥락이다. 
<br>

![image](https://user-images.githubusercontent.com/49298791/73643006-10ea3c80-46b6-11ea-82e9-a2ae79ead641.png)

- 이제는 what backpropagation doing에 대해 알아볼 건데, 가장 간단한 형태를 알아보기 위해 1 output unit을 둔다. (k=1이므로 summaion은 필요없다) 또한 regularization term을 없애 식을 간단히 만들어주기 위해 $lambda=0$으로 둔다. 이렇게 되면 cost function은 logistic에서 squared error을 구하는 것과 비슷한 형태와 같이 된다)
<br>

![image](https://user-images.githubusercontent.com/49298791/73643047-21021c00-46b6-11ea-9775-a28407618e05.png)

- $\delta$는 a에 대한 “error”을 의미한다. 또한 이 $\delta$값은 cost function에 대해 z로 partial derivitive를 구한 것과 같은 의미를 가진다. 즉 cost function에서의 x에 해당하는 값이 계속 바뀐다고 본다.
- backpropagation computing방법으로 계산한다고 했을 때 $delta^2$를 계산한다고 하는 것을 예로 들어본다. (결국 delta는 error을 의미하는 것이므로 weight를 준만큼 error를 더 받는다는 것을 알 수가 있음)

![image](https://user-images.githubusercontent.com/49298791/73643075-2e1f0b00-46b6-11ea-8286-b056d67eaa56.png)
<br>
## 2. Backpropagation in practice
**(1) implementation note : unrolling parameters**<br>
- Octave에서 reshape()를 이용하여 벡터를 matrix의 형태로 변환하는 방법에 대한 설명


**(2) Gradient checking**<br>
- BP를 이용하여 nural network의 cost function의 partial derivitive를 구하는 방법을 프로그램으로 구현하면 버그가 생기기 쉽다
- 이때 사용하는 것이 gradient checking으로 FP, BP의 구현이 완벽함을 보일수가 있다. 
- 기울기에 대한 근사치를 구해 비교하면서 검증하는 방법이다.(일종의 검증하는 방법)
- 매우작은 $\epsilon$에 대해 $\delta-\epsilon$과 $\delta+\epsilon$사이의 기울기를 구해 gradient와 근사한 값을 구하는 것이다. 

![image](https://user-images.githubusercontent.com/49298791/73643094-3d05bd80-46b6-11ea-8515-bd8f1c06a5d5.png)

- 이제 theta값이 n개의 vector로 이루어진 값이라고 하면, 각각의 partial derivitive는 아래와 같이 나타낼 수가 있다. (여러개의 theta값에 대해 각각의 $\epsilon$을 계산한 값과 동일하다.
![image](https://user-images.githubusercontent.com/49298791/73643125-47c05280-46b6-11ea-8ddd-8d99c27b7c7d.png)

- 즉 마지막에서 gradient checking을 이용해 구한 gradApprox와 실제 BP([partial derivitive를 구하는 가장 효율적인 방법]를 이용해 구한 gradient인 Dvec과 비슷한지를 검사한다. 
![image](https://user-images.githubusercontent.com/49298791/73643150-560e6e80-46b6-11ea-8c66-54bfefe6f93f.png)

- implement note
1. implement BP to compute DVec
2. implement numerical gradient chek to compute gradApprox
3. make sure they give similar values
4. turn off gradient cheking using BP code for learning

**(3) Random initialization** <br>
- gradient descent함수를 사용하라 때, initial theta값을 사용해야 한다. 이 값은 어떻게 지정할까에 대한 방법을 설명한다. 
- initial theta=zeros(n,1)로 두면, 작동하지 않을 것이다. 모든 유닛의 값이 같아지기 때문이다. 오류($\delta$)값이 같아지고 partial derivitave값도 같아지므로 모든 유닛이 같은 값을 가지고 반복이 된다. 
- 결국 내가 가진 모든 hidden unit이 같은 계산을 하므로 하나의 feature에 대해 중복된 연산만 반복한다(hidden unit이 의미가 없어지므로 애초에 neural network가 사용될 필요가 없어지는 경우이다. )
<br>
- 위와 같은 문제를 해결하기 위해 initial theta를 주는 방법이 _**random initialization**_이다. 

![image](https://user-images.githubusercontent.com/49298791/73643187-66bee480-46b6-11ea-8417-f45d5e3a8fbc.png)

- 즉 정리하자면 minimized theta값에 대하여 randomized된 initialized theta값을 고르고 이것을 바탕으로 시작하여 BP적용+ gradient cheking으로 검증하는 방법이 적용된다. 

**(4)Putting it together**<br>
neural network를 적용하는데 사용되는 overall과정을 전부 설명한다.<br>

#### 1. pick a network architecture(connectivly pattern between neurons)
output unit과 input unit은 class와 feature의 수로 결정이 되므로, 나머지 결정해야할 부분은 hidden unit과 hidden layer의 수이다. 
또 기본적으로 1개의 hidden layer을 사용가거나 1개 이상을 사용한다면 같은 수의 hidden unit을 사용하는 것이 비용면에서 가장 좋다. (몇개를 선정하는 것에 대한 것은 optimized값을 식은 있으나, 나중에 설명한다) <br>

![image](https://user-images.githubusercontent.com/49298791/73643210-73433d00-46b6-11ea-8b61-b6b0b0bbeb68.png)

#### 2. Training a neural network(앞과정에서 설명한 순서동일)
![image](https://user-images.githubusercontent.com/49298791/73643242-7f2eff00-46b6-11ea-920e-c8fba342f8dc.png)

- 하지만 결국 grdient descent에 local minimum값을 가질 수도 있다. 하지만 local의 경우도 good이 될 수 있으므로 크게 신경쓰지 않는다. 
![image](https://user-images.githubusercontent.com/49298791/73643268-89e99400-46b6-11ea-8865-63c56564878b.png)

![image](https://user-images.githubusercontent.com/49298791/73643289-91a93880-46b6-11ea-8dad-8f3c0fdf43f8.png)

- 1장부터 gradient를 설명하기 위한 언덕그림을 참고하면, gradient descent가 하는 일은 언덕을 내려가는 일이고(기울기를 낮게 가도록 하는 것) BP는 방향을 잡아주는 일이다(오차 d의 값이 적어지도록 방향을 잡아준다, 최소의 cost function을 가지도록 방향을 잡아주는 일을 한다고 본다.)
- 따라서 신경망에 gradient descent를 사용한다 하더라도 적당히 좋은 optimum을 찾게 된다. 

## 3. Autonomous Driving
- 무인 운전을 신경망으로 해결하는 방법에 대한 예.

## reference
Machine learning my Andrew Ng, Coursera